








import pandas as pd
DATASET_PATH = "./Student_Performance.csv"


df = pd.read_csv(DATASET_PATH, true_values=['Yes'], false_values=['No'])
f"L'ensemble de donn√©es se compose de {df.shape[0]} lignes et {df.shape[1]} colonnes"


df.sample(n=10, replace=True, random_state=1)


df.describe()





df.info()


df[df.select_dtypes('int64').columns] = df.select_dtypes('int64').astype('int8')
df[df.select_dtypes('float64').columns] = df.select_dtypes('float64').astype('float32')
df.info()





import plotly.express as px


agg_df = df.groupby("Hours Studied")['Performance Index'].mean()

fig = px.bar(agg_df, y="Performance Index", x=agg_df.index, title="Average Performance Distribution by Hours Studied", range_y=[40, 70])
fig.show()


agg_df = df.groupby("Previous Scores")['Performance Index'].mean()

fig = px.bar(agg_df, y="Performance Index", x=agg_df.index, title="Average Performance Distribution by Previous Scores")
fig.show()


agg_df = df.groupby("Extracurricular Activities")['Performance Index'].mean()

fig = px.bar(agg_df, y="Performance Index", x=agg_df.index, title="Average Performance Distribution by Extracurricular Activities", range_y=[54, 56])
fig.show()


agg_df = df.groupby("Sleep Hours")['Performance Index'].mean()

fig = px.bar(agg_df, y="Performance Index", x=agg_df.index, title="Average Performance Distribution by Sleep Hours", range_y=[53, 57])
fig.show()


agg_df = df.groupby("Sample Question Papers Practiced")['Performance Index'].mean()

fig = px.bar(agg_df, y="Performance Index", x=agg_df.index, title="Average Performance Distribution by Sample Question Papers Practiced", range_y=[52, 58])
fig.show()





corr_matrix = df.corr()
fig = px.imshow(corr_matrix, text_auto=True, color_continuous_scale='Blues', title="Correlation Matrix", height=800)
fig.show()





from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures
from sklearn.model_selection import KFold, GridSearchCV
from sklearn.linear_model import LinearRegression, SGDRegressor
from sklearn.tree import DecisionTreeRegressor





linear = Pipeline(steps=[
    ("poly", PolynomialFeatures()),
    ("linear_regression", LinearRegression())
])
sgd = SGDRegressor()
tree = DecisionTreeRegressor()
estimators=[
  ("linear_regression", linear),
  ("sgd", sgd),
  ("tree", tree)
]





linear_params = {
    'poly__degree': [2,3,4,5]
}
sgd_params = {
    'loss': ['squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],
    'penalty': ['l1', 'l2', 'elasticnet'],
    'alpha': [0.1, 0.01, 0.0001, 0.00001]
}
tree_params = {
    'criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],
    'max_depth': [2, 5, 7]
}
param_grid = [
    linear_params,
    sgd_params,
    tree_params
]
param_grid = [[params] for params in param_grid]





def run_cv(estimator_name, estimator, params):
  cv = GridSearchCV(estimator, params,
                    cv=KFold(20),
                    scoring=[
                        "r2",
                        "neg_mean_absolute_error",
                        "neg_mean_squared_error",
                        "neg_root_mean_squared_error"],
                    refit="r2")

  print(f"Lancer entrainement pour {estimator_name}...")
  cv.fit(
      X=df.drop(["Performance Index"], axis=1),
      y=df["Performance Index"]
  )
  result_df = pd.DataFrame(cv.cv_results_)
  result_df = result_df.sort_values(by="mean_score_time")
  #print(result_df.columns)
  print("Resultats")
  print(result_df[["params", "mean_test_r2", "std_test_r2"]].head(5))
  return cv.best_score_, cv.best_params_, cv.best_estimator_





scores = []
for estimator_, params in zip(estimators, param_grid):
  estimator_name, estimator = estimator_
  score = run_cv(estimator_name, estimator, params)
  scores.append((estimator_name, score))


import matplotlib.pyplot as plt


plt.figure(figsize=(10, 6))
model_names = [estimator_name for estimator_name, _ in scores]
r2_scores = [score[0] for _, score in scores]

plt.barh(model_names, r2_scores, color='skyblue')
plt.xlabel('Best R2 Score')
plt.title('Best R2 Score Comparison for Each Estimator')
plt.xlim(0.96, 1)
plt.grid(True)
plt.show()

for estimator_name, score in scores:
    best_params = score[1]
    print(f"Best parameters for {estimator_name}: {best_params}")


model_names = [estimator_name for estimator_name, _ in scores]
r2_scores = [score[0] for _, score in scores]

plt.plot(model_names, r2_scores, marker='o', linestyle='-', color='b')
plt.xlabel('Estimator')
plt.ylabel('Score')
plt.title('Estimator Performance')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()


max_score = 0
params = {}
estimator = ""
for estimator_name, score in scores:
   value, param_grid, _ = score

   max_score = max(max_score, value)
   if max_score == value:
      params = param_grid
      estimator = estimator_name

print(estimator, f"{max_score:.1%}", params)
